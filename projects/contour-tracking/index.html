<!DOCTYPE html>
<html lang="en">
  <head>
    <!-- Meta tags -->
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <!-- HTML Meta Tags -->
    <title>Contour Tracking</title>
    <meta
      name="description"
      content="https://junbongjang.github.io/projects/contour-tracking/"
    />
    <meta
      property="og:image"
      content="assets/architecture.png"
    />
    <meta property="og:image:type" content="image/png" />
    <meta property="og:image:width" content="1704" />
    <meta property="og:image:height" content="636" />
    <meta property="og:type" content="website" />
    <meta
      property="og:title"
      content="Unsupervised Contour Tracking of Live Cells by Mechanical and Cycle Consistency Losses"
    />
    <meta
      property="og:description"
      content="Analyzing the dynamic changes of cellular morphology is important for understanding the various functions and characteristics of live cells including stem cells and metastatic cancer cells.
      To this end, we need to track all points on the highly deformable cellular contour in every frame of live cell video. 
      Local shapes and textures on the contour are not evident, and their motions are complex often with expansion and contraction of local contour features.
      The prior arts for optical flow or deep point set tracking are unsuited due to the fluidity of cells and previous deep contour tracking does not consider point correspondence.
      We propose the first deep learning-based tracking of cellular (or more generally viscoelastic materials) contours with point correspondence by fusing dense representation between two contours with cross attention.
      Since it is impractical to manually label dense tracking points on the contour, unsupervised learning comprised of the mechanical and cyclical consistency losses is proposed to train our contour tracker.
      The mechanical loss forcing the points to move perpendicular to the contour effectively helps out.  
      For quantitative evaluation, we labeled sparse tracking points along the contour of live cells from two live cell datasets taken with phase contrast and confocal fluorescence microscopes. Our contour tracker quantitatively outperforms compared methods by a large margin and produces qualitatively more favorable results."
    />
    <meta name="twitter:card" content="summary_large_image" />
    <meta
      name="twitter:title"
      content="Unsupervised Contour Tracking of Live Cells by Mechanical and Cycle Consistency Losses"
    />
    <meta
      name="twitter:description"
      content="Analyzing the dynamic changes of cellular morphology is important for understanding the various functions and characteristics of live cells including stem cells and metastatic cancer cells.
      To this end, we need to track all points on the highly deformable cellular contour in every frame of live cell video. 
      Local shapes and textures on the contour are not evident, and their motions are complex often with expansion and contraction of local contour features.
      The prior arts for optical flow or deep point set tracking are unsuited due to the fluidity of cells and previous deep contour tracking does not consider point correspondence.
      We propose the first deep learning-based tracking of cellular (or more generally viscoelastic materials) contours with point correspondence by fusing dense representation between two contours with cross attention.
      Since it is impractical to manually label dense tracking points on the contour, unsupervised learning comprised of the mechanical and cyclical consistency losses is proposed to train our contour tracker.
      The mechanical loss forcing the points to move perpendicular to the contour effectively helps out.  
      For quantitative evaluation, we labeled sparse tracking points along the contour of live cells from two live cell datasets taken with phase contrast and confocal fluorescence microscopes. Our contour tracker quantitatively outperforms compared methods by a large margin and produces qualitatively more favorable results."
    />
    <meta
      name="twitter:image"
      content="assets/architecture.png"
    />
    <link
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css"
      rel="stylesheet"
      integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3"
      crossorigin="anonymous"
    />
    <link
      href="https://fonts.googleapis.com/css?family=Lato|Varela+Round|Open+Sans"
      rel="stylesheet"
      type="text/css"
    />
    <link rel="icon" type="image/x-icon" href="assets/jellyfish_icon.ico">
    <!-- Bootstrap JS -->
    <script
      src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"
      integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p"
      crossorigin="anonymous"
    ></script>
    <!-- Customized style -->
    <style>
      html * {
        color: #333;
        font-family: "Lato", sans-serif;
      }
      table.results td {
        color: #888;
        font-size: 90%;
      }
      .mtitle {
        margin-top: 0;
        margin-bottom: 0;
        font-family: "Varela Round", sans-serif;
        color: #4d4d4d;
        font-size: 50px;
        line-height: 80px;
        font-weight: 600;
        letter-spacing: 3px;
      }
      .msubtitle {
        margin-top: -30px;
        margin-bottom: -20px;
        font-size: 23px;
        line-height: 65px;
        letter-spacing: 2px;
      }
      .mneurips {
        color: #aaa;
        font-size: 20px;
      }
      .mauthors {
        font-size: 16px;
        font-weight: 400;
        line-height: 15px;
      }
      .mauthors_affiliation {
        margin-top: -12px;
        margin-bottom: 24px;
        font-family: "Open Sans", sans-serif;
        font-size: 12px;
        line-height: 15px;
      }
      .darker_bg {
        padding-top: 32px;
        padding-bottom: 32px;
        background-color: #f5f5f5;
      }
      .nav-link {
        color: #333;
      }
      .nav-link a:hover,
      a:hover,
      a:active {
        color: #888 !important;
      }
      .accordion-button:not(.collapsed) {
        color: inherit;
        background: #f5f5f5;
      }
      .accordion-button:not(.collapsed)::after {
        filter: brightness(0%) invert(70%);
      }
      .accordion-button:focus {
        box-shadow: inherit;
      }
    </style>
  </head>

  <body>
    <a
      href="https://github.com/JunbongJang/contour-tracking"
      class="github-corner"
      aria-label="View source on GitHub"
      ><svg
        width="80"
        height="80"
        viewBox="0 0 250 250"
        style="
          fill: #151513;
          color: #fff;
          position: absolute;
          top: 0;
          border: 0;
          right: 0;
        "
        aria-hidden="true"
      >
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path
          d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
          fill="#fff"
          style="transform-origin: 130px 106px"
          class="octo-arm"
        ></path>
        <path
          d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
          fill="#fff"
          class="octo-body"
        ></path></svg></a
    ><style>
      .github-corner:hover .octo-arm {
        animation: octocat-wave 560ms ease-in-out;
      }
      @keyframes octocat-wave {
        0%,
        100% {
          transform: rotate(0);
        }
        20%,
        60% {
          transform: rotate(-25deg);
        }
        40%,
        80% {
          transform: rotate(10deg);
        }
      }
      @media (max-width: 500px) {
        .github-corner:hover .octo-arm {
          animation: none;
        }
        .github-corner .octo-arm {
          animation: octocat-wave 560ms ease-in-out;
        }
      }
    </style>
    <div class="container-fluid my-5 mx-auto" style="max-width: 1000px">
      <div class="row">

        <h1 class="display-8 text-center mtitle">Contour Tracking</h1>
        <h1 class="display-8 text-center msubtitle mt-2 mb-2 lh-sm">
          Unsupervised Contour Tracking of Live Cells<br>by Mechanical and Cycle Consistency Losses
        </h1>
      </div>

      <div class="row mt-2">
        <div class="display-8 text-center mneurips">CVPR 2023</div>
      </div>
      <br>

      <div
        class="row text-center mt-3 mx-auto mauthors"
        style="max-width: 800px"
      />
        <div class="col-md-4">
          <a href="https://junbongjang.github.io/"> Junbong Jang </a>
        </div>
        <div class="col-md-4">
          <a href="https://research.childrenshospital.org/kwonmoo-lee"> Kwonmoo Lee </a>
        </div>
        <div class="col-md-4">
          <a href="https://sites.google.com/view/tkkim/home"> Tae-Kyun (T-K) Kim </a>
        </div>
      </div>
      <div class="row text-center mt-3 mx-auto" style="max-width: 800px">
        <div class="col-md-4 d-none d-md-block mauthors_affiliation">
          KAIST
        </div>
        <div class="col-md-4 d-none d-md-block mauthors_affiliation">
          Boston Children's Hospital<br>Harvard Medical School
        </div>
        <div class="col-md-4 d-none d-md-block mauthors_affiliation">KAIST<br>Imperial College London</div>
      </div>
      <div class="row mt-2 text-center">
        <a class="nav-link col-3"></a>
        <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Jang_Unsupervised_Contour_Tracking_of_Live_Cells_by_Mechanical_and_Cycle_CVPR_2023_paper.pdf" class="nav-link col-3">
          <svg style="width: 48px; height: 48px" viewBox="0 0 24 24">
            <path
              fill="currentColor"
              d="M16 0H8C6.9 0 6 .9 6 2V18C6 19.1 6.9 20 8 20H20C21.1 20 22 19.1 22 18V6L16 0M20 18H8V2H15V7H20V18M4 4V22H20V24H4C2.9 24 2 23.1 2 22V4H4M10 10V12H18V10H10M10 14V16H15V14H10Z"
            /></svg
          ><br />
          Paper
        </a>
        <a href="https://github.com/JunbongJang/contour-tracking/" class="nav-link col-3">
          <svg style="width: 48px; height: 48px" viewBox="0 0 24 24">
            <path
              fill="currentColor"
              d="M12,2A10,10 0 0,0 2,12C2,16.42 4.87,20.17 8.84,21.5C9.34,21.58 9.5,21.27 9.5,21C9.5,20.77 9.5,20.14 9.5,19.31C6.73,19.91 6.14,17.97 6.14,17.97C5.68,16.81 5.03,16.5 5.03,16.5C4.12,15.88 5.1,15.9 5.1,15.9C6.1,15.97 6.63,16.93 6.63,16.93C7.5,18.45 8.97,18 9.54,17.76C9.63,17.11 9.89,16.67 10.17,16.42C7.95,16.17 5.62,15.31 5.62,11.5C5.62,10.39 6,9.5 6.65,8.79C6.55,8.54 6.2,7.5 6.75,6.15C6.75,6.15 7.59,5.88 9.5,7.17C10.29,6.95 11.15,6.84 12,6.84C12.85,6.84 13.71,6.95 14.5,7.17C16.41,5.88 17.25,6.15 17.25,6.15C17.8,7.5 17.45,8.54 17.35,8.79C18,9.5 18.38,10.39 18.38,11.5C18.38,15.32 16.04,16.16 13.81,16.41C14.17,16.72 14.5,17.33 14.5,18.26C14.5,19.6 14.5,20.68 14.5,21C14.5,21.27 14.66,21.59 15.17,21.5C19.14,20.16 22,16.42 22,12A10,10 0 0,0 12,2Z"
            /></svg
          ><br />
          Code
        </a>
        <a class="nav-link col-3"></a>
      </div>


      <br>
      <div class="row">
        <div class="col-md-12 mt-2">
          
          <div style="position: relative; padding-top: 56.25%">
            <iframe src="https://www.youtube.com/embed/UWmd74OSTzM?&autoplay=1&loop=1&mute=1" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
            style="
                position: absolute;
                top: 0;
                left: 0;
                width: 100%;
                height: 100%;
              "
            allowfullscreen></iframe>
          </div>
          
          <i>best viewed in Full HD</i>
        </div>
      </div>

      <div class="my-5">
        <h2>Abstract</h2>
        <p>
          Analyzing the dynamic changes of cellular morphology is important for understanding the various functions and characteristics of live cells including stem cells and metastatic cancer cells.
   To this end, we need to track all points on the highly deformable cellular contour in every frame of live cell video. 
   Local shapes and textures on the contour are not evident, and their motions are complex often with expansion and contraction of local contour features.
   The prior arts for optical flow or deep point set tracking are unsuited due to the fluidity of cells and previous deep contour tracking does not consider point correspondence.
   We propose the first deep learning-based tracking of cellular (or more generally viscoelastic materials) contours with point correspondence by fusing dense representation between two contours with cross attention.
   Since it is impractical to manually label dense tracking points on the contour, unsupervised learning comprised of the mechanical and cyclical consistency losses is proposed to train our contour tracker.
   The mechanical loss forcing the points to move perpendicular to the contour effectively helps out.  
   For quantitative evaluation, we labeled sparse tracking points along the contour of live cells from two live cell datasets taken with phase contrast and confocal fluorescence microscopes. Our contour tracker quantitatively outperforms compared methods by a large margin and produces qualitatively more favorable results.
        </p>

        <center>
          <img src="assets/architecture.png" width=95% />
        </center>
      </div>

      <div class="my-5">
        <h2>Video Results</h2>
        <div class="text-center mt-3 col-md-12">
          <div style="position: relative; padding-top: 56.25%">
            <iframe src="https://www.youtube.com/embed/umKQ90fOtjQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen
            style="
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
          "></iframe>
          </div>
        </div>

        <div class="text-center mt-3 col-md-12">
          <div style="position: relative; padding-top: 56.25%">
            <iframe src="https://www.youtube.com/embed/wtpHB8mS01w" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen
            style="
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
          "></iframe>
          </div>
        </div>

        <div class="text-center mt-3 col-md-12">
          <div style="position: relative; padding-top: 56.25%">
            <iframe src="https://www.youtube.com/embed/44aU8JPD6G4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen
            style="
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
          "></iframe>
          </div>
        </div>
        
        <div class="text-center mt-3 col-md-12">
          <div style="position: relative; padding-top: 56.25%">
            <iframe src="https://www.youtube.com/embed/M2n_p2zSwMs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen
            style="
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
          "></iframe>
          </div>
        </div>
        
        <div class="text-center mt-3 col-md-12">
          <div style="position: relative; padding-top: 56.25%">
            <iframe src="https://www.youtube.com/embed/qTb2VkHhvC4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen
            style="
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
          "></iframe>
          </div>
        </div>

      </div>

      <div class="row my-5">
        <h2>Citation</h2>
        <div class="col-md-12 mt-3">
<pre>
@inproceedings{jang2023contourtracking,
  title={Unsupervised Contour Tracking of Live Cells by Mechanical and Cycle Consistency Losses},
  author={Jang, Junbong and Lee, Kwonmoo and Kim, Tae-Kyun},
  booktitle={CVPR},
  year={2023}
}</pre>
        </div>
      </div>

      <div class="text-center">
        <hr />
        <small>Inspired by
          <a href="https://jyunlee.github.io/projects/implicit-two-hands/">Im2Hands</a>
        </small>
      </div>

    </div>
  </body>
</html>